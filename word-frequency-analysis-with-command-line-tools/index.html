<!DOCTYPE html>
<html>

<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>Word frequency analysis with command line tools</title>
<meta name="viewport" content="width=device-width">
<meta name="description" content="A blog about programming">
<link rel="canonical" href="http://davidxmoody.com/word-frequency-analysis-with-command-line-tools/">
<link rel="stylesheet" href="/css/main-7910edc4decc7a43c4aff4d2dc05131b.css">
<meta name="wot-verification" content="fdff4a26070b9df2fd1a" />
</head>

<body>

<div class="wrapper">
<header class="site-header">
<h1><a href="/">David Moody</a></h1>
<p>A blog about programming</p>
</header>

<div class="content">
<article>
<header>
<h1>Word frequency analysis with command line tools</h1>
<p><em>Feb 20, 2015</em></p>
</header>

<p>I have previously written about <a href="/writing-speeds/">writing speeds</a>. I think one of the best ways to improve is to utilise <a href="/better-vim-abbreviations/">abbreviations</a> and other <a href="/vim-auto-capitalisation/">tricks</a>. </p>
<p>I recently looked into a shorthand system called <a href="http://www.easyscript.com/">EasyScript</a>. The most important part I took from it is to develop a set of short abbreviations for the most common words. They give a set of suggested abbreviations but I wasn&#39;t happy with them. Instead, I wanted to analyse my own writing to find my most commonly used words and phrases. </p>
<!--more-->
<h2 id="a-simple-python-script">A simple Python script</h2>
<p>A little while ago, I wrote the following Python script to do just that. It utilises the <code>Counter</code> object and <code>fileinput</code> module to simplify the collection process. It also strips out unnecessary punctuation and converts to lower-case. </p>
<pre><code class="lang-python3"><div class="highlight"><pre><span class="c">#!/usr/bin/env python3</span>

<span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">fileinput</span>

<span class="n">word_tallies</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>

<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">fileinput</span><span class="o">.</span><span class="n">input</span><span class="p">():</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s">&#39;.,!?[]()*{}-&lt;&gt;:;&quot;</span><span class="se">\&#39;</span><span class="s">&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>
    <span class="n">word_tallies</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>

<span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">word_tallies</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">200</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">count</span><span class="p">,</span> <span class="n">word</span><span class="p">)</span>
</pre></div>

</code>
</pre>
<h2 id="bash-script">Bash script</h2>
<p>The above Python script works perfectly. However, I wanted to try implementing the same thing with Linux command line tools. Roughly working from <a href="http://www.generation5.org/content/2004/nlpUnix.asp">this blog post</a>, I devised the following script:</p>
<pre><code class="lang-bash"><div class="highlight"><pre><span class="c">#!/bin/bash</span>

<span class="nv">IN_FILE</span><span class="o">=</span>./input.txt

tr -sc <span class="s2">&quot;[A-Z][a-z][0-9]&#39;&quot;</span> <span class="s1">&#39;[\012*]&#39;</span> &lt; <span class="s2">&quot;$IN_FILE&quot;</span> <span class="p">|</span> <span class="se">\</span>
  tr <span class="s1">&#39;[A-Z]&#39;</span> <span class="s1">&#39;[a-z]&#39;</span> <span class="p">|</span> <span class="se">\</span>
  sort <span class="p">|</span> uniq -c <span class="p">|</span> sort -nr <span class="p">|</span> <span class="se">\</span>
  head -n200
</pre></div>

</code>
</pre>
<p>The <code>tr</code> command is a little tricky. Normally the <code>tr</code> command would replace any characters in the first set with the corresponding character in the second set. However, the <code>-c</code> option specifies to use the <em>compliment</em> of the first set (i.e. any characters <em>not</em> appearing in the first set). Thus any non-word character is replaced with <code>&#39;[\012]&#39;</code> (a newline character). </p>
<p>The <code>-s</code> option specifies to replace a sequence of one or more matches with <em>only a single occurrence</em> of the replacement character. This avoids empty lines in the output when multiple punctuation characters appear in the input. The result is a list of words separated by newlines and stripped of punctuation. </p>
<p>The second call of <code>tr</code> replaces all upper-case letters with their lower-case counterparts. This avoids duplicates due to words sometimes being at the start of a sentence. </p>
<p>It is then piped to <code>sort</code> and <code>uniq -c</code>. This counts the occurrences of each word. <code>uniq -c</code> is designed to print out a count as soon as it sees something different to the last line it saw. That means you need to first pipe to <code>sort</code> to avoid duplicate counts.</p>
<p>It is then piped to <code>sort -nr</code> which sorts in <em>descending numerical order</em>. Then finally to <code>head -n200</code> to prevent the output from getting too large. </p>
<h2 id="bigrams-and-trigrams">Bigrams and trigrams</h2>
<p>Bigrams and trigrams are just sequences of two or three words that occur together (<a href="http://en.wikipedia.org/wiki/N-gram">see n-gram</a>). They can be just as interesting as single word frequencies. </p>
<p>I&#39;m only just getting into <code>awk</code> after reading <a href="http://ferd.ca/awk-in-20-minutes.html">this pretty good introductory tutorial</a>. In the following script, an additional step has been added to replace the stream of words with a stream of word pairs.</p>
<p>The first <code>awk</code> statement prints out the previous word and the current word on the same line (skipping the very first word). The second statement just sets the previous word for use on the next line. I&#39;m sure it could be prettier but it works well. </p>
<pre><code class="lang-bash"><div class="highlight"><pre><span class="c">#!/bin/bash</span>

<span class="nv">IN_FILE</span><span class="o">=</span>./input.txt

tr -sc <span class="s2">&quot;[A-Z][a-z][0-9]&#39;&quot;</span> <span class="s1">&#39;[\012*]&#39;</span> &lt; <span class="s2">&quot;$IN_FILE&quot;</span> <span class="p">|</span> <span class="se">\</span>
  tr <span class="s1">&#39;[A-Z]&#39;</span> <span class="s1">&#39;[a-z]&#39;</span> <span class="p">|</span> <span class="se">\</span>
  awk -- <span class="s1">&#39;prev!=&quot;&quot; { print prev,$0; } { prev=$0; }&#39;</span> <span class="p">|</span> <span class="se">\</span>
  sort <span class="p">|</span> uniq -c <span class="p">|</span> sort -nr <span class="p">|</span> <span class="se">\</span>
  head -n200
</pre></div>

</code>
</pre>
<p>This next script prints out trigrams instead of bigrams using the same kind of method. This could also be done with a for loop for n-grams of any size.</p>
<pre><code class="lang-bash"><div class="highlight"><pre><span class="c">#!/bin/bash</span>

<span class="nv">IN_FILE</span><span class="o">=</span>./input.txt

tr -sc <span class="s2">&quot;[A-Z][a-z][0-9]&#39;&quot;</span> <span class="s1">&#39;[\012*]&#39;</span> &lt; <span class="s2">&quot;$IN_FILE&quot;</span> <span class="p">|</span> <span class="se">\</span>
  tr <span class="s1">&#39;[A-Z]&#39;</span> <span class="s1">&#39;[a-z]&#39;</span> <span class="p">|</span> <span class="se">\</span>
  awk -- <span class="s1">&#39;first!=&quot;&quot;&amp;&amp;second!=&quot;&quot; { print first,second,$0; } { first=second; second=$0; }&#39;</span> <span class="p">|</span> <span class="se">\</span>
  sort <span class="p">|</span> uniq -c <span class="p">|</span> sort -nr <span class="p">|</span> <span class="se">\</span>
  head -n200
</pre></div>

</code>
</pre>
<h2 id="did-i-learn-anything-useful-">Did I learn anything useful?</h2>
<p>Here is the output when run on my diary:</p>
<pre><code><div class="highlight"><pre>  <span class="mi">71219</span> <span class="nx">i</span>
  <span class="mi">42731</span> <span class="nx">to</span>
  <span class="mi">41792</span> <span class="nx">the</span>
  <span class="mi">33638</span> <span class="nx">and</span>
  <span class="mi">30602</span> <span class="nx">a</span>
  <span class="mi">27413</span> <span class="nx">it</span>
  <span class="mi">21500</span> <span class="nx">of</span>
  <span class="mi">20162</span> <span class="nx">that</span>
  <span class="mi">18174</span> <span class="nx">my</span>
  <span class="mi">13745</span> <span class="k">for</span>
  <span class="mi">13059</span> <span class="nx">was</span>
  <span class="mi">12664</span> <span class="k">in</span>
  <span class="mi">11078</span> <span class="nx">think</span>
  <span class="mi">10189</span> <span class="kd">with</span>
  <span class="mi">10149</span> <span class="nx">have</span>
   <span class="mi">9553</span> <span class="nx">just</span>
   <span class="mi">9416</span> <span class="nx">on</span>
   <span class="mi">9182</span> <span class="nx">also</span>
   <span class="mi">9157</span> <span class="nx">i</span><span class="err">&#39;</span><span class="nx">m</span>
   <span class="mi">8967</span> <span class="nx">is</span>
   <span class="mi">8535</span> <span class="nx">be</span>
   <span class="mi">8226</span> <span class="nx">but</span>
</pre></div>

</code>
</pre>
<p>Not many surprises given how common all of these words are. Still, there are significant time savings to be had. I have slowly been training myself to type with certain abbreviations over the past few months. For example <code>&quot;t&quot; -&gt; &quot;to&quot;</code>, <code>&quot;h&quot; -&gt; &quot;the&quot;</code> and <code>&quot;d&quot; -&gt; &quot;and&quot;</code>. Similarly for most of the words in that list. </p>
<p>There are a total of 5,854,003 characters in my diary. By calculating the number of keystrokes saved per abbreviation and multiplying by the number of times that word appears in my diary, I estimate that I could have saved 559,440 characters with my above abbreviations alone. </p>
<p>That&#39;s <strong>10%</strong> of my total keystrokes. Combined with other abbreviations and typing tricks, I think I could save 20-30% of all keystrokes. </p>
<p>Personally, I think a 20% saving is <em>easily</em> worth the time and effort it takes to learn. I expect to be typing for my entire adult life. If I type 300,000 words a year for the next 50 years (conservative estimate) then I could save myself 16,000,000 total keystrokes over my entire lifetime. That&#39;s equivalent to about 60,000 minutes saved or 1,000 hours.</p>
<h2 id="bigram-results">Bigram results</h2>
<p>I&#39;m actually mildly disappointed with the bigrams I extracted. They are mostly just combinations of the most frequently occurring words. It&#39;s interesting but not especially useful. Here&#39;s a sample:</p>
<pre><code><div class="highlight"><pre>   <span class="mi">8726</span> <span class="nx">i</span> <span class="nx">think</span>
   <span class="mi">5039</span> <span class="nx">that</span> <span class="nx">i</span>
   <span class="mi">4517</span> <span class="nx">i</span> <span class="nx">was</span>
   <span class="mi">3726</span> <span class="nx">i</span> <span class="nx">don</span><span class="err">&#39;</span><span class="nx">t</span>
   <span class="mi">3599</span> <span class="nx">to</span> <span class="k">do</span>
   <span class="mi">3493</span> <span class="nx">want</span> <span class="nx">to</span>
   <span class="mi">3446</span> <span class="nx">going</span> <span class="nx">to</span>
   <span class="mi">3391</span> <span class="nx">it</span> <span class="nx">was</span>
   <span class="mi">3388</span> <span class="nx">of</span> <span class="nx">the</span>
   <span class="mi">3364</span> <span class="k">in</span> <span class="nx">the</span>
</pre></div>

</code>
</pre>
<p>And trigrams:</p>
<pre><code><div class="highlight"><pre>   <span class="mi">2305</span> <span class="nx">i</span> <span class="nx">think</span> <span class="nx">i</span>
   <span class="mi">1483</span> <span class="nx">i</span> <span class="nx">want</span> <span class="nx">to</span>
   <span class="mi">1474</span> <span class="nx">i</span><span class="s1">&#39;m going to</span>
<span class="s1">   1279 a lot of</span>
<span class="s1">    882 i think it</span>
<span class="s1">    874 i don&#39;</span><span class="nx">t</span> <span class="nx">know</span>
    <span class="mi">758</span> <span class="nx">be</span> <span class="nx">able</span> <span class="nx">to</span>
    <span class="mi">724</span> <span class="k">for</span> <span class="nx">a</span> <span class="nx">walk</span>
    <span class="mi">709</span> <span class="nx">i</span> <span class="nx">don</span><span class="err">&#39;</span><span class="nx">t</span> <span class="nx">think</span>
    <span class="mi">682</span> <span class="nx">i</span> <span class="nx">think</span> <span class="nx">the</span>
</pre></div>

</code>
</pre>
</article>

</div>

<div class="push"></div>
</div>

<footer class="site-footer">
<p>
<br>
<a href="/feed.xml">RSS</a> |
<a href="https://github.com/davidxmoody">GitHub</a> |
<a href="mailto:david@davidxmoody.com">Email</a>
</p>
<p>
This blog is available under a
<a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons License</a>
</p>
</footer>

</body>

</html>